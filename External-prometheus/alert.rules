groups:
  - name: HostDown
    rules:
      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Sensor is down"
          description: "The instance {{ $labels.instance }} has been down for more than 5 minutes."

      - alert: HostCpuStealNoisyNeighbor
        expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
          description: "CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}"

      - alert: HostDiskWillFillIn24Hours
        expr: '(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
          description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}"

      - alert: HostHighCpuLoad
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: Host high CPU load (instance {{ $labels.instance }})
          description: "CPU load is > 80%\n  VALUE = {{ $value }}"

      - alert: HostInodesWillFillIn24Hours
        expr: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host inodes will fill in 24 hours (instance {{ $labels.instance }})
          description: "Filesystem is predicted to run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}"

      - alert: HostMemoryUnderMemoryPressure
        expr: rate(node_vmstat_pgmajfault[1m]) > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host memory under memory pressure (instance {{ $labels.instance }})
          description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}"

      - alert: HostOutOfDiskSpace
        expr: '(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of disk space (instance {{ $labels.instance }})
          description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}"

      - alert: HostOutOfInodes
        expr: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0'
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of inodes (instance {{ $labels.instance }})
          description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}"

      - alert: HostOutOfMemory
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of memory (instance {{ $labels.instance }})
          description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}"

      - alert: HostUnusualDiskReadLatency
        expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk read latency (instance {{ $labels.instance }})
          description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}"

      - alert: HostUnusualDiskReadRate
        expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk read rate (instance {{ $labels.instance }})
          description: "Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}"

      - alert: HostUnusualDiskWriteLatency
        expr: rate(node_disk_write_time_seconds_total{device!~"mmcblk.+"}[1m]) / rate(node_disk_writes_completed_total{device!~"mmcblk.+"}[1m]) > 0.1 and rate(node_disk_writes_completed_total{device!~"mmcblk.+"}[1m]) > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk write latency (instance {{ $labels.instance }})
          description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}"

      - alert: HostUnusualDiskWriteRate
        expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk write rate (instance {{ $labels.instance }})
          description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}"

      - alert: HostUnusualNetworkThroughputIn
        expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual network throughput in (instance {{ $labels.instance }})
          description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}"

      - alert: HostUnusualNetworkThroughputOut
        expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual network throughput out (instance {{ $labels.instance }})
          description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}"

  - name: Cinder
    rules:
      - alert: CinderAgentDown
        expr: |
          openstack_cinder_agent_state != 1
        labels:
          severity: P4
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down.

      - alert: CinderAgentDown
        for: 5m
        expr: |
          openstack_cinder_agent_state != 1
        labels:
          severity: P3
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down for 5 minutes.  This can affect volume operations so it must
            be resolved as quickly as possible.

      - alert: CinderAgentDisabled
        for: 1h
        expr: |
          openstack_cinder_agent_state{adminState!="enabled"}
        labels:
          severity: P5
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` disabled"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            has been disabled for 60 minutes.  This can affect volume operations so it must be resolved
            as quickly as possible.

      - alert: CinderVolumeInError
        for: 24h
        expr: |
          openstack_cinder_volume_status{status=~"error.*"}
        labels:
          severity: P4
        annotations:
          summary: "[`{{`{{$labels.id}}`}}`] Volume in ERROR state"
          description: >
            The volume `{{`{{$labels.id}}`}}` has been in ERROR state for over 24 hours.  It must
            be cleaned up or removed in order to provide a consistent customer experience.

  - name: neutron
    rules:
      - alert: NeutronAgentDown
        expr: |
          openstack_neutron_agent_state != 1
        labels:
          severity: P4
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down.

      - alert: NeutronAgentDown
        for: 5m
        expr: |
          openstack_neutron_agent_state != 1
        labels:
          severity: P3
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down for 5 minutes. This can affect network operations so it must
            be resolved as quickly as possible.

      - alert: NeutronAgentDisabled
        for: 1h
        expr: |
          openstack_neutron_agent_state{adminState!="up"}
        labels:
          severity: P5
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` disabled"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            has been disabled for 60 minutes.  This can affect network operations so it must be resolved
            as quickly as possible.

      - alert: NeutronBindingFailedPorts
        expr: |
          openstack_neutron_port{binding_vif_type="binding_failed"} != 0
        labels:
          severity: P3
        annotations:
          summary: "[`{{`{{$labels.device_owner}}`}}`] `{{`{{$labels.mac_address}}`}}` binding failed"
          description: >
            The NIC `{{`{{$labels.mac_address}}`}}` of `{{`{{$labels.device_owner}}`}}`
            has binding failed port now.

      - alert: NeutronNetworkOutOfIPs
        expr: |
          sum by (network_id) (openstack_neutron_network_ip_availabilities_used{project_id!=""}) / sum by (network_id) (openstack_neutron_network_ip_availabilities_total{project_id!=""}) * 100 > 80
        labels:
          severity: P4
        annotations:
          summary: "[`{{`{{$labels.network_name}}`}}`] `{{`{{$labels.subnet_name}}`}}` running out of IPs"
          description: >
            The subnet `{{`{{$labels.subnet_name}}`}}` within `{{`{{$labels.network_name}}`}}`
            is currently at `{{`{{$value}}`}}`% utilization.  If the IP addresses run out, it will
            impact the provisioning of new ports.

  - name: nova
    rules:
      - alert: NovaAgentDown
        expr: |
          openstack_nova_agent_state != 1
        labels:
          severity: P4
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down.

      - alert: NovaAgentDown
        for: 5m
        expr: |
          openstack_nova_agent_state != 1
        labels:
          severity: P3
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` down"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            is being reported as down.  This can affect compute operations so it must be resolved
            as quickly as possible.

      - alert: NovaAgentDisabled
        for: 1h
        expr: |
          openstack_nova_agent_state{adminState!="enabled"}
        labels:
          severity: P5
        annotations:
          summary: "[`{{`{{$labels.hostname}}`}}`] `{{`{{$labels.exported_service}}`}}` disabled"
          description: >
            The service `{{`{{$labels.exported_service}}`}}` running on `{{`{{$labels.hostname}}`}}`
            has been disabled for 60 minutes.  This can affect compute operations so it must be resolved
            as quickly as possible.

      - alert: NovaCapacity
        for: 6h
        expr: |
          sum (
            openstack_nova_memory_used_bytes
            + on(hostname) group_left(adminState)
              (0 * openstack_nova_agent_state{exported_service="nova-compute",adminState="enabled"})
          )
          /
          sum (
            openstack_nova_memory_available_bytes
            + on(hostname) group_left(adminState)
              (0 * openstack_nova_agent_state{exported_service="nova-compute",adminState="enabled"})
          )
          * 100 > 75
        labels:
          severity: P4
        annotations:
          summary: "[nova] Capacity risk"
          description: >
            The cloud capacity is currently at `{{`{{$value}}`}}` which means there is a risk of running
            out of capacity due to the timeline required to add new nodes.  Please ensure that adequate
            amount of infrastructure is assigned to this deployment to prevent this.

      - alert: NovaFailureRisk
        for: 6h
        expr: |
          sum(openstack_nova_memory_available_bytes - openstack_nova_memory_used_bytes)
        labels:
          severity: P4
        annotations:
          summary: "[nova] Potential resource exhaustion"
          description: >
            Free memory available in Nova is below threshold. Current free memory is `{{ $value }}` bytes.
